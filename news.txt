How Many Replication Studies are Enough?
http://www.nature.com/news/how-many-replication-studies-are-enough-1.19461
2016-02-26
replication tests
Researchers on social media ask at what point replication efforts go from useful to wasteful. The problem of irreproducibility in science has gained widespread attention, but one aspect that is discussed less often is how to find the right balance between replicating findings and moving a field forward from well-established ones.


A Bayesian Perspective on the Reproducibility Project: Psychology
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0149794
2016-02-26
replication tests
We revisit the results of the recent Reproducibility Project: Psychology by the Open Science Collaboration. We compute Bayes factors—a quantity that can be used to express comparative evidence for an hypothesis but also for the null hypothesis—for a large subset (N = 72) of the original papers and their corresponding replication attempts.


A Practical Guide for Improving transparency and Reproducibility in Neuroimaging Research
http://dx.doi.org/10.1101/039354
2016-02-14
reproducibility guide, guide, neuroimaging
Recent years have seen an increase in alarming signals about the lack of replicability in neuroscience, psychology, and other related fields. To avoid a widespread crisis in our field and consequent loss of credibility in the public eye, we need to improve how we do science. This article aims to be a practical guide for researchers at any stage of their careers that will help them make their research more reproducible and transparent while minimizing the additional effort that this might require. The guide covers three major topics in open science (data, code, and publications) and offers practical advice as well as highlighting advantages of adopting more open research practices that go beyond improved transparency and reproducibility.


A New Group Is Dedicated To Double-Checking Scientists' Work
http://www.newsy.com/videos/a-new-group-is-dedicated-to-double-checking-scientists-work/
2016-02-12

For the past decade, scientists have been worried about the so-called replication crisis. Enter the Preclinical Reproducibility and Robustness channel. The website launched the first week in February with the goal of publishing the results of replication studies. The journal wants to keep scientists accountable for their work.


BioPolicy Summit tackles reproducibility of science issues
https://biodesign.asu.edu/news/biopolicy-summit-tackles-reproducibility-science-issues
2016-02-12

The 2016 GBSI Summit—“Research Reproducibility: Innovative Solutions to Drive Quality” welcomed premiere life science thought leaders, including Arizona State University biomarker researcher Joshua LaBaer, MD, PhD, and science correspondent and moderator Richard Harris (currently on leave from National Public Radio as a visiting scholar this spring at Arizona State University), to explore the driving forces and profound impacts behind the issues.


It’s a kind of magic: how to improve adherence to reporting guidelines
http://blogs.biomedcentral.com/bmcseriesblog/2016/02/12/kind-magic-improve-adherence-reporting-guidelines/
2016-02-12

Finding a relevant reporting guideline for a study can be very difficult. Here we introduce a pilot experiment starting for some of the BMC-series journals which aims to overcome this issue.


Friday: Reusing Data and Making Your Data Reusable
http://data-services.hosting.nyu.edu/updates/lyd16-friday/
2016-02-12

This blog post is apart of the Love Your Data campaign #LYD16, a global and cross-institution awareness campaign for open data, research reproducibility, and research data management. This post features ReproMatch and ReproZip as important tools for achieving reproducibility. 


A Noob's Guide to Reproducibility
http://www.stat.berkeley.edu/~stark/Seminars/reproNE16.htm#1
2016-02-10

A presentation by Philip B. Stark of University of California at Berkeley that gives a great 101-style look into what the everyday researcher can do to make their science more reproducible. 


Science is "show me," not "trust me"
http://www.bitss.org/2015/12/31/science-is-show-me-not-trust-me/
2016-02-10

A blog post from Philip B. Stark, Associate Dean of the Division of Mathematical and Physical Sciences, UC Berkeley Professor of Statistics, and winner of one of BITSS’ Leamer-Rosenthal Prizes for Open Social Science. This post discuss the core elements of reproducibility; its principles and practices.


Startup unveils tools to improve trial reproducibility
http://www.mmm-online.com/dataanalytics/startup-unveils-tools-to-improve-trial-reproducibility/article/471977/
2016-02-09

Elemental Machines, which develops smart laboratory technology, launched a new suite of tools that that measure environmental variables such as temperature and humidity—both of which are not traditionally accounted for in scientific experiments. By “debugging” the lab environment, the company believes it can improve experimental reproducibility, therefore reducing the time and cost of marketing new drugs and therapies. Elemental Machines recently raised $2.5 million in seed capital to support the development of the new suite of tools, which is called the EM Suite.


Co-founder of Center for Scientific Integrity speaks Feb. 19 about issues in scholarly publishing
http://www.montana.edu/news/15963/co-founder-of-center-for-scientific-integrity-speaks-feb-19-about-issues-in-scholarly-publishing
2016-02-05

Adam Marcus, cofounder of Retraction Watch and the Center for Scientific Integrity, will give a free lecture about issues in scholarly science publishing at 4 p.m. Friday, Feb. 19, in 103 Reid Hall at Montana State University.


Misfit Founders Raise $2.5M to 'Debug the Physical World' With New Startup
http://bostinno.streetwise.co/2016/02/03/misfit-wearables-founders-raise-2-5m-for-elemental-machines/
2016-02-03

Elemental Machines, a venture based in Boston and San Francisco, has come out of stealth mode. The startup says it's raised $2.5 million in seed from investors including Founders Fund’s FF Angel, PayPal co-founder Max Levchin and Project 11 Ventures. And now it’s ready to change the way our world does science, providing the infrastructure that will ensure experiment reproducibility for researchers.


Reproducibility: A tragedy of errors
http://www.nature.com/news/reproducibility-a-tragedy-of-errors-1.19264
2016-02-03

Mistakes in peer-reviewed papers are easy to find but hard to fix, report David B. Allison and colleagues: "In the course of assembling weekly lists of articles in our field, we began noticing more peer-reviewed articles containing what we call substantial or invalidating errors. These involve factual mistakes or veer substantially from clearly accepted procedures in ways that, if corrected, might alter a paper's conclusions."


ReproZip Poster Accepted at FORCE2016
https://www.force11.org/meetings/force2016/program/agenda
2016-01-27

Fernando Chirigati and Remi Rampin's poster "Enhancing Scholarly Communication with ReproZip" was recently accepted at FORCE2016, a conference from FORCE11 a community of scholars, librarians, archivists, publishers and research funders that has arisen organically to help facilitate the change toward improved knowledge creation and sharing. 


GBSI Doubles Down on Research Reproducibility at Annual BioPolicy Summit and Webcast in Washington, DC, February 9th
http://www.newswise.com/articles/gbsi-doubles-down-on-research-reproducibility-at-annual-biopolicy-summit-and-webcast-in-washington-dc-february-9th
2016-01-27

The Summit will also introduce GBSI’s Reproducibility2020, an action plan for the biomedical research community to significantly improve the quality of research by 2020 targeting: 1) improved validation and standardization of biological reagents; 2) better tools and technologies to expand open access for reporting and sharing protocols and data; and 3) increased training that emphasizes rigorous study design and practice.


Reproducibility from a Mostly Selfish Point of View
https://discuss.ropensci.org/t/slides-and-some-thoughts-on-a-talk-about-reproducibility/294
2016-01-27

A talk given by Noam Ross: "Why was, as the title suggests, primarily focused on the benefits of reproducibility to us, and I proceeded from avoiding negatives (risk avoidance) to creating positives (more impact). In How I tried to be very high-level, talking about major concepts in reproducibility, and then talking generally about the tools that I have used for each, emphasizing that they may not be the right tools for everyone. Then we had a discussion about the most promising areas and tools to start with."


New Shotgun Mass Spec Workflow Could Improve Reproducibility of Protein Quantitation in DDA
https://www.genomeweb.com/proteomics-protein-research/new-shotgun-mass-spec-workflow-could-improve-reproducibility-protein
2016-01-21

Researchers at Sweden's Karolinska Institute and Royal Institute of Technology have developed a new data analysis workflow for shotgun mass spec that could help improve the technique's quantitative reproducibility. Detailed in a paper published this month in Molecular & Cellular Proteomics, the approach uses a new quality scoring system that allows for more reliable recovery of missing data points across multiple mass spec runs.


noWorkflow Demo Video Released
https://www.youtube.com/watch?v=lyJnbwdArJM
2016-01-20

A video demonstrating noWorkflow, a non-intrusive tool that allows researchers to capture a variety of provenance information and utilize the analyses it supports, including graph-based visualization, differencing over provenance trails, and inference queries.


FASEB Issues Recommendations on Reproducibility
http://www.faseb.org/Resources-for-the-Public/News-Room/Article-Detail-View/tabid/1014/ArticleId/1251/FASEB-Issues-Recommendations-on-Reproducibility.aspx
2016-01-14

Today the Federation of American Societies for Experimental Biology (FASEB) issued Enhancing Research Reproducibility, a set of recommendations aimed to promote the reproducibility and transparency of biomedical and biological research. 


Lecture: A Noob's Guide to Reproducibility
http://bids.berkeley.edu/events/noobs-guide-reproducibility
2016-01-11

Lecture on January 25, 2016; 4:00pm to 5:00pm; 3110 Etcheverry Hall at Berkely Institute of Data Science. What does it mean to work reproducibly and transparently? Why bother? Whom does it benefit, and how? What will it cost me? What work habits will I need to change? Will I need to learn new tools? What resources help? What's the simplest thing I can do to make my work more reproducible? How can I move my discipline, my institution, and science as a whole towards reproducibility?


Upcoming Webinar: Scientific Rigor and Data Reproducibility
https://www.sfn.org/news-and-calendar/news-and-calendar/news/professional-development/upcoming-webinar-scientific-rigor-and-data-reproducibility
2016-01-11

The topics of scientific rigor and data reproducibility have been increasingly covered in the scientific and mainstream media, and are being addressed by publishers, professional organizations, and funding agencies, including NIH. This webinar – the first in a series titled Training Modules to Enhance Data Reproducibility (TMEDR) – will address topics of scientific rigor as they pertain to pre-clinical neuroscience research. 


R's role in science breakthrough: reproducibility of psychology studies
http://blog.revolutionanalytics.com/2016/01/rs-role-in-science-breakthrough-reproducibility-of-psychology-studies.html
2016-01-08

R is a natural fit for a reproducibility project like this: as a scripting language, the R script itself provides a reproducible documentation of every step of the process. (Revolution R Open, Microsoft's enhanced R distribution, additionally includes features to facilitate reproducibility when using R packages.) The R script used for the psychology replication project describes and executes the process for checking the results of the papers.


"PEOPLE LIKE STORIES" A SHORT FILM ABOUT REPRODUCIBILITY
https://politicalsciencereplication.wordpress.com/2016/01/07/people-like-stories-a-short-film-about-reproducibility/
2016-01-07

We need mathematical help to tell the difference between a real discovery and the illusion of one. Fellow of the Royal Society and future President of the Royal Statistical Society, Sir David Spiegelhalter visits Dr Nicole Janz  to discuss reproducibility in scientific publications.


A Proactive Approach to Reproducibility with Evidence-Based Research on Research
https://www.plos.org/a-proactive-approach-to-reproducibility-with-evidence-based-research-on-research/
2016-01-06

The new Meta-Research Section in PLOS Biology is not the only example of how PLOS strives to improve the scientific endeavor through innovative communication efforts. PLOS has always recognized that publication of studies that reproduce published work or null results, either confirming or refuting the original result, is essential for progress in research. In fact, the largest journal at PLOS, PLOS ONE, is one of only a handful of publications that actively encourage these types of submissions with The Missing Pieces Collection.


Reproducibility Project Named Among Top Scientific Achievements of 2015
https://www.psychologicalscience.org/index.php/publications/observer/obsonline/reproducibility-project-named-among-top-scientific-achievements-of-2015.html
2016-01-05

The journal Science has named a major attempt to replicate 100 papers published in top-tier psychology journals as one of the "breakthroughs of the year" for 2015.


Why Scientists Need to Fail
http://www.psmag.com/nature-and-technology/science-needs-to-fail
2015-12-22

As researchers think about how to improve reproducibility, it's important to remember that failure is a crucial part of the scientific process.


Winning Video from GBSI #authenticate Campaign Will Promote Reproducibility Among Younger Generation of Biomedical Researchers
http://www.newswise.com/articles/winning-video-from-gbsi-authenticate-campaign-will-promote-reproducibility-among-younger-generation-of-biomedical-researchers
2015-12-17

The Global Biological Standards Institute (GBSI) today announced the winner of its #authenticate video competition to promote cell authentication in biomedical research is Michael Ge, from West Covina, California


Reproducibility at SC16 with the Student Cluster Competition
http://www.nist.gov/itl/ssd/is/upload/NRE-2015-00-SC16SCC_CfP_slide.pdf
2015-12-17

Replication and reproducibility of experimental computer science results in peer-reviewed paper is gaining relevance in the HPC community. SC, the leading conference in the field, wants to promote and support replication and reproducibility through a new initiative that aims to integrate aspects of past technical papers into the Student Cluster Competition (SCC). SC16 invites authors of technical papers accepted at past SC conferences, including SC15, to submit proposals for case studies based on applications and tests in their SC paper that can be transformed into benchmarks for the SCC. This initiative provides SC authors with the unique opportunity to further promote their published research as an example of replicable and reproducible experimental computer science.


Clinical Genetics Has a Big Problem That's Affecting People's Lives
http://www.theatlantic.com/science/archive/2015/12/why-human-genetics-research-is-full-of-costly-mistakes/420693/
2015-12-16

Over the last decade, there’s been a lot of talk about reproducibility problems in science — about published results that turn out to be false alarms. In fields like psychology, neuroscience, and cell biology, these errors can send scientists down unproductive paths, waste time and money, and pollute headlines with misleading claims. “But I get much more exercised about reproducibility problems in clinical genetics, because those have massive and real-time consequences for thousands of families,” says MacArthur.


Emphasize Sex in Research, orders National Institutes of Health
http://synapse.ucsf.edu/articles/2015/12/16/emphasize-sex-research-orders-national-institutes-health
2015-12-16

While experiments may be published even in a top scientific journal, other researchers who attempt to repeat the same experiments under the same conditions often find contradicting results. As a measure of this, a recent study attempted to reproduce psychology publications and successfully replicated only 39 out of 100 studies.It turns out that excluding sex in experimental design may have contributed to reproducibility issues. Furthermore, sex can also have a biological impact on our scientific understanding and influence how well early biological studies translate into advances in human medicine.


Year in review: Scientists tackle the irreproducibility problem
https://www.sciencenews.org/article/year-review-scientists-tackle-irreproducibility-problem
2015-12-15

Experimental results that don’t hold up to replication have caused consternation among scientists for years, especially in the life and social sciences (SN: 1/24/15, p. 20). In 2015 several research groups examining the issue reported on the magnitude of the irreproducibility problem. The news was not good.


Reproducibility in Medical IVA
https://osf.io/5afwm/
2015-12-09

Project on Reproducibility and Robustness of the Empirical Instrumental Variables Literature in Medicine. 


Reproducibility: Experimental mismatch in neural circuits
http://www.nature.com/nature/journal/vaop/ncurrent/full/nature16323.html
2015-12-09

The finding that acute and chronic manipulations of the same neural circuit can produce different behavioural outcomes poses new questions about how best to analyse these circuits.


Translation, cultural adaptation and reproducibility of the Oxford Shoulder Score questionnaire for Brazil, among patients with rheumatoid arthritis.
http://www.ncbi.nlm.nih.gov/pubmed/26648280
2015-12-08

Although shoulder questionnaires validated for Brazil do exist, none of them are aimed at populations with rheumatic disease. We believe that the Oxford Shoulder Score (OSS) may be useful in this population. The objective of this study was to translate the OSS, adapt it to Brazilian culture and test its reproducibility.


Letting Out Steam: Reproducibility Problems
https://www.digital-science.com/blog/perspectives/letting-out-steam-reproducibility-problems/
2015-12-08

The first part of the STM innovations seminar focused on the problems of reproducibility in science. For some years now, there have been voices of concern noting that when previously reported results are tested, the data very often doesn’t come out the same way. During the seminar, Andrew Hufton of Scientific Data went so far as to state that progress in the pharmaceutical sciences is being held back by lack of reliability in the basic literature. 


Big problems for common fMRI thresholding methods
http://reproducibility.stanford.edu/big-problems-for-common-fmri-thresholding-methods/
2015-12-08

Stanford Center for Reproducible Neuroscience: A new preprint has been posted to the ArXiv that has very important implications and should be required reading for all fMRI researchers.  Anders Eklund, Tom Nichols, and Hans Knutson applied task fMRI analyses to a large number of resting fMRI datasets, in order to identify the empirical corrected “familywise” Type I error rates observed under the null hypothesis for both voxel-wise and cluster-wise inference.  What they found is shocking: While voxel-wise error rates were valid, nearly all cluster-based parametric methods (except for FSL’s FLAME 1) have greatly inflated familywise Type I error rates.  This inflation was worst for analyses using lower cluster-forming thresholds (e.g. p=0.01) compared to higher thresholds, but even with higher thresholds there was serious inflation.  This should be a sobering wake-up call for fMRI researchers, as it suggests that the methods used in a large number of previous publications suffer from exceedingly high false positive rates (sometimes greater than 50%).  


How do we fix bad science?
https://cosmosmagazine.com/society/how-do-we-fix-bad-science
2015-12-07

Independently verifying research can help science regain its credibility, argues Laurie Zoloth. His paper: “Why Most Published Research Findings Are False”, was published in August 2005, in PLOS Medicine. It became one of the journal’s most-cited articles. While climate sceptics, anti-vaccination campaigners and the rest of the pseudo-science community have dined out on this paper, arguably it has been a shot in the arm for science. 


ReproZip 1.0.3 released
https://github.com/ViDA-NYU/reprozip/releases/tag/1.0.3
2015-12-02

A new version of ReproZip has been released, adding some bugfixes and options to pass environment variables to the experiment.


Cancer reproducibility project scales back ambitions
http://www.nature.com/news/cancer-reproducibility-project-scales-back-ambitions-1.18938
2015-12-02

The Reproducibility Project: Cancer Biology aims to get a better, quantitative estimate of the reproducibility of important work and to understand the challenges such efforts present. Begun in 2013, the project is run jointly by the Center for Open Science (COS) in Charlottesville, Virginia, and Science Exchange in Palo Alto, California. 


Reproducibility of Research: Get Started
http://campusguides.lib.utah.edu/reproducibility
2015-12-01

A research guide from the University of Utah on making research reproducible.

Brian Nosek on the Reproducibility Project
http://www.econtalk.org/archives/2015/11/brian_nosek_on.html
2015-11-16

Brian Nosek of the University of Virginia and the Center for Open Science talks with EconTalk host Russ Roberts about the Reproducibility Project.


Promises, Promises, and Cell Lines: Life Sciences Researchers Talk About the Obvious Solution—Cell-Line Authentication—but They Fail To Implement It
http://www.genengnews.com/gen-articles/promises-promises-and-cell-lines/5631/
2015-11-15

According to a 2013 report from the American Association for the Advancement of Science, $115 billion is spent annually in the United States on life science research. Fifty percent of this total is spent on preclinical research, half of which—$28 billion—is not reproducible.


Speaking of Research Integrity 
http://www.the-scientist.com/?articles.view/articleNo/44424/title/Speaking-of-Research-Integrity/
2015-11-06

Panelists discuss reproducibility, data-sharing, and encouraging early-career researchers at this year’s World Science Forum.


ReproZip Demo Tutorial Video
https://youtu.be/-zLPuwCHXo0
2015-11-05

This is a demo video showing how to pack and unpack experiments with ReproZip.


Bioethics and the reproducibility crisis
http://www.bioedge.org/bioethics/bioethics-and-the-reproducibility-crisis/11632
2015-10-31

According to the mayor of Chicago, Rahm Emanuel, who is linked to bioethics through his bioethicist brother Ezekiel Emanuel, "You never let a serious crisis go to waste.” In this case the crisis is the reproducibility of published results in the biological and medical sciences. According to a recent comment in Nature, “An unpublished 2015 survey by the American Society for Cell Biology found that more than two-thirds of respondents had on at least one occasion been unable to reproduce published results. Biomedical researchers from drug companies have reported that one-quarter or fewer of high-profile papers are reproducible.”


Improving the reproducibility of biomedical research
http://www.bbsrc.ac.uk/news/policy/2015/151029-pr-improving-reproducibility-of-biomedical-research/
2015-10-29

The Academy of Medical Sciences has published a new joint report on how the reproducibility and reliability of research can be improved. Recent reports in the general and scientific media show there is increasing concern within the biomedical research community about the lack of reproducibility of key research findings.


Reproducibility in science — where the MRC comes in
http://www.insight.mrc.ac.uk/2015/10/29/reproducibility-in-science-where-the-mrc-comes-in/
2015-10-29

The MRC and a group of partner organisations have today published a report and joint statement  about the reproducibility and reliability of research, and what can be done to improve them. Here, Jim Smith, MRC Deputy Chief Executive and Director of Strategy, thinks about how discussions of reproducibility offer us the opportunity to improve the way science is done.


MSDSE Reproducibility Zotero Bibliography
https://www.zotero.org/groups/msdse-reproducibility
2015-10-05

This group is for sharing reproducibility related citeable resources within the Moore and Sloan Data Science Environments reproducibility working group effort.


New Study: Scientific Researchers Are Not Always Reliable
http://www.utahpeoplespost.com/2015/08/new-study-scientific-researches-are-not-always-reliable/
2015-08-29

Researchers tested the credibility of past investigations reaching the conclusion of a new study: scientific researches are not always reliable. Few of the past studies could be replicated showing that some researches are either too biased or too distinctive to make a statement in history.


The Results of the Reproducibility Project Are In. They’re Not Good.
http://chronicle.com/article/The-Results-of-the/232695
2015-08-28

A decade ago, John P.A. Ioannidis published a provocative and much-discussed paper arguing that most published research findings are false. It’s starting to look like he was right.


Massive Study Reports Challenges in Reproducing Published Psychology Findings
https://news.virginia.edu/content/massive-study-reports-challenges-reproducing-published-psychology-findings
2015-08-27

A study that sought to replicate 100 findings published in three prominent psychology journals has found that, across multiple criteria, independent researchers could replicate less than half of the original findings. In some cases this may call into question the validity of some scientific findings, but it may also point to the difficulty of conducting effective replications and achieving reproducible results.


Reproducibility blues
https://dx.doi.org/10.15252/embj.201570090
2015-04-11

Research findings advance science only if they are significant, reliable and reproducible. Scientists and journals must publish robust data in a way that renders it optimally reproducible. Reproducibility has to be incentivized and supported by the research infrastructure but without dampening innovation.


Program Seeks to Nurture 'Data Science Culture' at Universities
http://bits.blogs.nytimes.com/2013/11/12/program-seeks-to-nurture-data-science-culture-at-universities/?_php=true&_type=blogs&smid=fb-share&_r=1
2013-11-12

In collaboration with the University of Washington (UW) and Berkeley, and under the sponsorship of the Moore and Sloan foundations, NYU is working on a new initiative to 'harness the potential of data scientists and big data'. As part of this initiative, we aim to increase awareness of sharing, preservation, provenance, and reproducibility best practices across UW, NYU, Berkeley campuses and encourage their adoption. 


Open-Access Deal for Particle Physics
http://www.nature.com/news/open-access-deal-for-particle-physics-1.11468
2012-09-24

"The entire field of particle physics is set to switch to open-access publishing, a milestone in the push to make research results freely available to readers."


Junk science? Most preclinical cancer studies don't replicate
http://www.readthehook.com/103149/junk-science-most-preclinical-cancer-studies-dont-replicate
2012-04-06

When a cancer study is published in a prestigious peer-reviewed journal, the implication is the findings are robust, replicable, and point the way toward eventual treatments. Consequently, researchers scour their colleagues' work for clues about promising avenues to explore. Doctors pore over the pages, dreaming of new therapies coming down the pike. Which makes a new finding that nine out of 10 preclinical peer-reviewed cancer research studies cannot be replicated all the more shocking and discouraging.


The Database Experiments Repository (DBXR) is Online
http://www.dbxr.org/
2012-01-01

This site serves as a repository for experiments related to database research. Currently, it supports the submission and review of results published at PVLDB and ACM Sigmod.


SIGMOD Repeatability Effort
http://effdas.itu.dk/repeatability/tuning.html
2012-01-01

As part of this project, in collaboration with Philippe Bonnet, we are using (and extending) our infrastructure to support the SIGMOD Repeatability effort. Below are some case studies that illustrate how authors can create provenance-rich and reproducible papers, and how reviewers can both reproduce the experiments and perform workability tests: packaging an experiment on a distributed database system (link in title).


How Bright Promise in Cancer Testing Fell Apart
http://www.nytimes.com/2011/07/08/health/research/08genes.html
2011-07-11

Research at Duke University in genomics that involved fighting cancer by looking for gene patterns that would determine which drugs would best attack a particular cancer (no more trial-and-error treatment, considered a breakthrough). This research turned out to be wrong, due to flaws in the research (found by statisticians); if the research was reproducible, errors could have been found earlier and the patients could have continued their treatment. 


It’s Science, but Not Necessarily Right
http://www.nytimes.com/2011/06/26/opinion/sunday/26ideas.html?_r=2
2011-06-25

NY article discussing the issues with scientific reproducibility: "Why? One simple answer is that it takes a lot of time to look back over other scientists’ work and replicate their experiments. Scientists are busy people, scrambling to get grants and tenure. As a result, papers that attract harsh criticism may nonetheless escape the careful scrutiny required if they are to be refuted."


Galois Conjugates of Topological Phases
http://arxiv.org/abs/1106.3267
2011-06-16

Professor Matthias Troyer (ETH Zurich) and his collaborators have published a number of papers whose results are fully reproducible. He is using VisTrails to both carry out the experiments and to package them for publication. 


The ALPS Project Release 2.0: Open Source Software for Strongly Correlated Systems
http://arxiv.org/pdf/1101.2646.pdf
2011-05-23

Professor Matthias Troyer (ETH Zurich) and his collaborators have published a number of papers whose results are fully reproducible. He is using VisTrails to both carry out the experiments and to package them for publication. 


Reproducible Research
http://magazine.amstat.org/blog/2011/01/01/scipolicyjan11
2011-01-01

The journal Biostatistics has an associate editor for reproducibility who can assign grades of merit to conditionally accepted papers: D: data are available, C: code is available, and R: the AE could run the code and reproduce the results without much effort.


Nobel Laureate Retracts Two Papers Unrelated to Her Prize
http://www.nytimes.com/2010/09/24/science/24retraction.html?_r=1&emc=eta1
2010-09-23

Linda B. Buck, who shared the 2004 Nobel Prize in Physiology or Medicine for deciphering the workings of the sense of smell, has retracted two scientific papers after she and her colleagues were unable to repeat the findings.
