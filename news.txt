Lecture: A Noob's Guide to Reproducibility
http://bids.berkeley.edu/events/noobs-guide-reproducibility
2016-01-11
Lecture on January 25, 2016; 4:00pm to 5:00pm; 3110 Etcheverry Hall at Berkely Institute of Data Science. What does it mean to work reproducibly and transparently? Why bother? Whom does it benefit, and how? What will it cost me? What work habits will I need to change? Will I need to learn new tools? What resources help? What's the simplest thing I can do to make my work more reproducible? How can I move my discipline, my institution, and science as a whole towards reproducibility?


Upcoming Webinar: Scientific Rigor and Data Reproducibility
https://www.sfn.org/news-and-calendar/news-and-calendar/news/professional-development/upcoming-webinar-scientific-rigor-and-data-reproducibility
2016-01-11
The topics of scientific rigor and data reproducibility have been increasingly covered in the scientific and mainstream media, and are being addressed by publishers, professional organizations, and funding agencies, including NIH. This webinar – the first in a series titled Training Modules to Enhance Data Reproducibility (TMEDR) – will address topics of scientific rigor as they pertain to pre-clinical neuroscience research. 


R's role in science breakthrough: reproducibility of psychology studies
http://blog.revolutionanalytics.com/2016/01/rs-role-in-science-breakthrough-reproducibility-of-psychology-studies.html
2016-01-08
R is a natural fit for a reproducibility project like this: as a scripting language, the R script itself provides a reproducible documentation of every step of the process. (Revolution R Open, Microsoft's enhanced R distribution, additionally includes features to facilitate reproducibility when using R packages.) The R script used for the psychology replication project describes and executes the process for checking the results of the papers.


A Proactive Approach to Reproducibility with Evidence-Based Research on Research
https://www.plos.org/a-proactive-approach-to-reproducibility-with-evidence-based-research-on-research/
2016-01-06
The new Meta-Research Section in PLOS Biology is not the only example of how PLOS strives to improve the scientific endeavor through innovative communication efforts. PLOS has always recognized that publication of studies that reproduce published work or null results, either confirming or refuting the original result, is essential for progress in research. In fact, the largest journal at PLOS, PLOS ONE, is one of only a handful of publications that actively encourage these types of submissions with The Missing Pieces Collection.


Reproducibility Project Named Among Top Scientific Achievements of 2015
https://www.psychologicalscience.org/index.php/publications/observer/obsonline/reproducibility-project-named-among-top-scientific-achievements-of-2015.html
2016-01-05
The journal Science has named a major attempt to replicate 100 papers published in top-tier psychology journals as one of the "breakthroughs of the year" for 2015.


Why Scientists Need to Fail
http://www.psmag.com/nature-and-technology/science-needs-to-fail
2015-12-22
As researchers think about how to improve reproducibility, it's important to remember that failure is a crucial part of the scientific process.


Winning Video from GBSI #authenticate Campaign Will Promote Reproducibility Among Younger Generation of Biomedical Researchers
http://www.newswise.com/articles/winning-video-from-gbsi-authenticate-campaign-will-promote-reproducibility-among-younger-generation-of-biomedical-researchers
2015-12-17
The Global Biological Standards Institute (GBSI) today announced the winner of its #authenticate video competition to promote cell authentication in biomedical research is Michael Ge, from West Covina, California


Reproducibility at SC16 with the Student Cluster Competition
http://www.nist.gov/itl/ssd/is/upload/NRE-2015-00-SC16SCC_CfP_slide.pdf
2015-12-17
Replication and reproducibility of experimental computer science results in peer-reviewed paper is gaining relevance in the HPC community. SC, the leading conference in the field, wants to promote and support replication and reproducibility through a new initiative that aims to integrate aspects of past technical papers into the Student Cluster Competition (SCC). SC16 invites authors of technical papers accepted at past SC conferences, including SC15, to submit proposals for case studies based on applications and tests in their SC paper that can be transformed into benchmarks for the SCC. This initiative provides SC authors with the unique opportunity to further promote their published research as an example of replicable and reproducible experimental computer science.


Clinical Genetics Has a Big Problem That's Affecting People's Lives
http://www.theatlantic.com/science/archive/2015/12/why-human-genetics-research-is-full-of-costly-mistakes/420693/
2015-12-16
Over the last decade, there’s been a lot of talk about reproducibility problems in science — about published results that turn out to be false alarms. In fields like psychology, neuroscience, and cell biology, these errors can send scientists down unproductive paths, waste time and money, and pollute headlines with misleading claims. “But I get much more exercised about reproducibility problems in clinical genetics, because those have massive and real-time consequences for thousands of families,” says MacArthur.


Emphasize Sex in Research, orders National Institutes of Health
http://synapse.ucsf.edu/articles/2015/12/16/emphasize-sex-research-orders-national-institutes-health
2015-12-16
While experiments may be published even in a top scientific journal, other researchers who attempt to repeat the same experiments under the same conditions often find contradicting results. As a measure of this, a recent study attempted to reproduce psychology publications and successfully replicated only 39 out of 100 studies.It turns out that excluding sex in experimental design may have contributed to reproducibility issues. Furthermore, sex can also have a biological impact on our scientific understanding and influence how well early biological studies translate into advances in human medicine.


Year in review: Scientists tackle the irreproducibility problem
https://www.sciencenews.org/article/year-review-scientists-tackle-irreproducibility-problem
2015-12-15
Experimental results that don’t hold up to replication have caused consternation among scientists for years, especially in the life and social sciences (SN: 1/24/15, p. 20). In 2015 several research groups examining the issue reported on the magnitude of the irreproducibility problem. The news was not good.


Reproducibility in Medical IVA
https://osf.io/5afwm/
2015-12-09
Project on Reproducibility and Robustness of the Empirical Instrumental Variables Literature in Medicine. 


Reproducibility: Experimental mismatch in neural circuits
http://www.nature.com/nature/journal/vaop/ncurrent/full/nature16323.html
2015-12-09
The finding that acute and chronic manipulations of the same neural circuit can produce different behavioural outcomes poses new questions about how best to analyse these circuits.


Translation, cultural adaptation and reproducibility of the Oxford Shoulder Score questionnaire for Brazil, among patients with rheumatoid arthritis.
http://www.ncbi.nlm.nih.gov/pubmed/26648280
2015-12-08
Although shoulder questionnaires validated for Brazil do exist, none of them are aimed at populations with rheumatic disease. We believe that the Oxford Shoulder Score (OSS) may be useful in this population. The objective of this study was to translate the OSS, adapt it to Brazilian culture and test its reproducibility.


Letting Out Steam: Reproducibility Problems
https://www.digital-science.com/blog/perspectives/letting-out-steam-reproducibility-problems/
2015-12-08
The first part of the STM innovations seminar focused on the problems of reproducibility in science. For some years now, there have been voices of concern noting that when previously reported results are tested, the data very often doesn’t come out the same way. During the seminar, Andrew Hufton of Scientific Data went so far as to state that progress in the pharmaceutical sciences is being held back by lack of reliability in the basic literature. 


Big problems for common fMRI thresholding methods
http://reproducibility.stanford.edu/big-problems-for-common-fmri-thresholding-methods/
2015-12-08
Stanford Center for Reproducible Neuroscience: A new preprint has been posted to the ArXiv that has very important implications and should be required reading for all fMRI researchers.  Anders Eklund, Tom Nichols, and Hans Knutson applied task fMRI analyses to a large number of resting fMRI datasets, in order to identify the empirical corrected “familywise” Type I error rates observed under the null hypothesis for both voxel-wise and cluster-wise inference.  What they found is shocking: While voxel-wise error rates were valid, nearly all cluster-based parametric methods (except for FSL’s FLAME 1) have greatly inflated familywise Type I error rates.  This inflation was worst for analyses using lower cluster-forming thresholds (e.g. p=0.01) compared to higher thresholds, but even with higher thresholds there was serious inflation.  This should be a sobering wake-up call for fMRI researchers, as it suggests that the methods used in a large number of previous publications suffer from exceedingly high false positive rates (sometimes greater than 50%).  


How do we fix bad science?
https://cosmosmagazine.com/society/how-do-we-fix-bad-science
2015-12-07
Independently verifying research can help science regain its credibility, argues Laurie Zoloth. His paper: “Why Most Published Research Findings Are False”, was published in August 2005, in PLOS Medicine. It became one of the journal’s most-cited articles. While climate sceptics, anti-vaccination campaigners and the rest of the pseudo-science community have dined out on this paper, arguably it has been a shot in the arm for science. 


ReproZip 1.0.3 released
https://github.com/ViDA-NYU/reprozip/releases/tag/1.0.3
2015-12-02
A new version of ReproZip has been released, adding some bugfixes and options to pass environment variables to the experiment.


Cancer reproducibility project scales back ambitions
http://www.nature.com/news/cancer-reproducibility-project-scales-back-ambitions-1.18938
2015-12-02
The Reproducibility Project: Cancer Biology aims to get a better, quantitative estimate of the reproducibility of important work and to understand the challenges such efforts present. Begun in 2013, the project is run jointly by the Center for Open Science (COS) in Charlottesville, Virginia, and Science Exchange in Palo Alto, California. 


Reproducibility of Research: Get Started
http://campusguides.lib.utah.edu/reproducibility
2015-12-01
A research guide from the University of Utah on making research reproducible.

Brian Nosek on the Reproducibility Project
http://www.econtalk.org/archives/2015/11/brian_nosek_on.html
2015-11-16
Brian Nosek of the University of Virginia and the Center for Open Science talks with EconTalk host Russ Roberts about the Reproducibility Project.


Promises, Promises, and Cell Lines: Life Sciences Researchers Talk About the Obvious Solution—Cell-Line Authentication—but They Fail To Implement It
http://www.genengnews.com/gen-articles/promises-promises-and-cell-lines/5631/
2015-11-15
According to a 2013 report from the American Association for the Advancement of Science, $115 billion is spent annually in the United States on life science research. Fifty percent of this total is spent on preclinical research, half of which—$28 billion—is not reproducible.


Speaking of Research Integrity 
http://www.the-scientist.com/?articles.view/articleNo/44424/title/Speaking-of-Research-Integrity/
2015-11-06
Panelists discuss reproducibility, data-sharing, and encouraging early-career researchers at this year’s World Science Forum.


ReproZip Demo Tutorial Video
https://youtu.be/-zLPuwCHXo0
2015-11-05
This is a demo video showing how to pack and unpack experiments with ReproZip.


Bioethics and the reproducibility crisis
http://www.bioedge.org/bioethics/bioethics-and-the-reproducibility-crisis/11632
2015-10-31
According to the mayor of Chicago, Rahm Emanuel, who is linked to bioethics through his bioethicist brother Ezekiel Emanuel, "You never let a serious crisis go to waste.” In this case the crisis is the reproducibility of published results in the biological and medical sciences. According to a recent comment in Nature, “An unpublished 2015 survey by the American Society for Cell Biology found that more than two-thirds of respondents had on at least one occasion been unable to reproduce published results. Biomedical researchers from drug companies have reported that one-quarter or fewer of high-profile papers are reproducible.”


Improving the reproducibility of biomedical research
http://www.bbsrc.ac.uk/news/policy/2015/151029-pr-improving-reproducibility-of-biomedical-research/
2015-10-29
The Academy of Medical Sciences has published a new joint report on how the reproducibility and reliability of research can be improved. Recent reports in the general and scientific media show there is increasing concern within the biomedical research community about the lack of reproducibility of key research findings.


Reproducibility in science — where the MRC comes in
http://www.insight.mrc.ac.uk/2015/10/29/reproducibility-in-science-where-the-mrc-comes-in/
2015-10-29
The MRC and a group of partner organisations have today published a report and joint statement  about the reproducibility and reliability of research, and what can be done to improve them. Here, Jim Smith, MRC Deputy Chief Executive and Director of Strategy, thinks about how discussions of reproducibility offer us the opportunity to improve the way science is done.


MSDSE Reproducibility Zotero Bibliography
https://www.zotero.org/groups/msdse-reproducibility
2015-10-05
This group is for sharing reproducibility related citeable resources within the Moore and Sloan Data Science Environments reproducibility working group effort.


New Study: Scientific Researchers Are Not Always Reliable
http://www.utahpeoplespost.com/2015/08/new-study-scientific-researches-are-not-always-reliable/
2015-08-29
Researchers tested the credibility of past investigations reaching the conclusion of a new study: scientific researches are not always reliable. Few of the past studies could be replicated showing that some researches are either too biased or too distinctive to make a statement in history.


The Results of the Reproducibility Project Are In. They’re Not Good.
http://chronicle.com/article/The-Results-of-the/232695
2015-08-28
A decade ago, John P.A. Ioannidis published a provocative and much-discussed paper arguing that most published research findings are false. It’s starting to look like he was right.


Massive Study Reports Challenges in Reproducing Published Psychology Findings
https://news.virginia.edu/content/massive-study-reports-challenges-reproducing-published-psychology-findings
2015-08-27
A study that sought to replicate 100 findings published in three prominent psychology journals has found that, across multiple criteria, independent researchers could replicate less than half of the original findings. In some cases this may call into question the validity of some scientific findings, but it may also point to the difficulty of conducting effective replications and achieving reproducible results.


Reproducibility blues
https://dx.doi.org/10.15252/embj.201570090
2015-04-11
Research findings advance science only if they are significant, reliable and reproducible. Scientists and journals must publish robust data in a way that renders it optimally reproducible. Reproducibility has to be incentivized and supported by the research infrastructure but without dampening innovation.


Program Seeks to Nurture 'Data Science Culture' at Universities
http://bits.blogs.nytimes.com/2013/11/12/program-seeks-to-nurture-data-science-culture-at-universities/?_php=true&_type=blogs&smid=fb-share&_r=1
2013-11-12
In collaboration with the University of Washington (UW) and Berkeley, and under the sponsorship of the Moore and Sloan foundations, NYU is working on a new initiative to 'harness the potential of data scientists and big data'. As part of this initiative, we aim to increase awareness of sharing, preservation, provenance, and reproducibility best practices across UW, NYU, Berkeley campuses and encourage their adoption. 


Open-Access Deal for Particle Physics
http://www.nature.com/news/open-access-deal-for-particle-physics-1.11468
2012-09-24
"The entire field of particle physics is set to switch to open-access publishing, a milestone in the push to make research results freely available to readers."


Junk science? Most preclinical cancer studies don't replicate
http://www.readthehook.com/103149/junk-science-most-preclinical-cancer-studies-dont-replicate
2012-04-06
When a cancer study is published in a prestigious peer-reviewed journal, the implication is the findings are robust, replicable, and point the way toward eventual treatments. Consequently, researchers scour their colleagues' work for clues about promising avenues to explore. Doctors pore over the pages, dreaming of new therapies coming down the pike. Which makes a new finding that nine out of 10 preclinical peer-reviewed cancer research studies cannot be replicated all the more shocking and discouraging.


The Database Experiments Repository (DBXR) is Online
http://www.dbxr.org/
2012-01-01
This site serves as a repository for experiments related to database research. Currently, it supports the submission and review of results published at PVLDB and ACM Sigmod.


SIGMOD Repeatability Effort
http://effdas.itu.dk/repeatability/tuning.html
2012-01-01
As part of this project, in collaboration with Philippe Bonnet, we are using (and extending) our infrastructure to support the SIGMOD Repeatability effort. Below are some case studies that illustrate how authors can create provenance-rich and reproducible papers, and how reviewers can both reproduce the experiments and perform workability tests: packaging an experiment on a distributed database system (link in title).


How Bright Promise in Cancer Testing Fell Apart
http://www.nytimes.com/2011/07/08/health/research/08genes.html
2011-07-11
Research at Duke University in genomics that involved fighting cancer by looking for gene patterns that would determine which drugs would best attack a particular cancer (no more trial-and-error treatment, considered a breakthrough). This research turned out to be wrong, due to flaws in the research (found by statisticians); if the research was reproducible, errors could have been found earlier and the patients could have continued their treatment. 


It’s Science, but Not Necessarily Right
http://www.nytimes.com/2011/06/26/opinion/sunday/26ideas.html?_r=2
2011-06-25
NY article discussing the issues with scientific reproducibility: "Why? One simple answer is that it takes a lot of time to look back over other scientists’ work and replicate their experiments. Scientists are busy people, scrambling to get grants and tenure. As a result, papers that attract harsh criticism may nonetheless escape the careful scrutiny required if they are to be refuted."


Galois Conjugates of Topological Phases
http://arxiv.org/abs/1106.3267
2011-06-16
Professor Matthias Troyer (ETH Zurich) and his collaborators have published a number of papers whose results are fully reproducible. He is using VisTrails to both carry out the experiments and to package them for publication. 


The ALPS Project Release 2.0: Open Source Software for Strongly Correlated Systems
http://arxiv.org/pdf/1101.2646.pdf
2011-05-23
Professor Matthias Troyer (ETH Zurich) and his collaborators have published a number of papers whose results are fully reproducible. He is using VisTrails to both carry out the experiments and to package them for publication. 


Reproducible Research
http://magazine.amstat.org/blog/2011/01/01/scipolicyjan11
2011-01-01
The journal Biostatistics has an associate editor for reproducibility who can assign grades of merit to conditionally accepted papers: D: data are available, C: code is available, and R: the AE could run the code and reproduce the results without much effort.


Nobel Laureate Retracts Two Papers Unrelated to Her Prize
http://www.nytimes.com/2010/09/24/science/24retraction.html?_r=1&emc=eta1
2010-09-23
Linda B. Buck, who shared the 2004 Nobel Prize in Physiology or Medicine for deciphering the workings of the sense of smell, has retracted two scientific papers after she and her colleagues were unable to repeat the findings.
